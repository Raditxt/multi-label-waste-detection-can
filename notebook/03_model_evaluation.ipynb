{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import Library yang Diperlukan ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json # Tambahan: untuk menyimpan JSON\n",
    "\n",
    "# Library TensorFlow dan Keras untuk memuat model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall, BinaryAccuracy # Metrik untuk multi-label\n",
    "\n",
    "# Library Scikit-learn untuk metrik evaluasi\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    PrecisionRecallDisplay\n",
    ")\n",
    "from sklearn.model_selection import train_test_split # Untuk split data (meskipun data sudah di-split sebelumnya, ini untuk konsistensi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0. Konfigurasi Global (Pastikan Konsisten) ---\n",
    "# Ini harus sama persis dengan konfigurasi saat Anda melatih model\n",
    "LABELS_FINAL = ['battery', 'organik', 'glass', 'cardboard', 'metal', 'paper', 'plastic', 'trash']\n",
    "\n",
    "# Path Dasar untuk Dataset\n",
    "# Asumsi skrip/notebook ini berada di 'notebooks/' dan dataset di 'dataset/'\n",
    "BASE_DIR_DATASET = os.path.abspath(os.path.join(os.getcwd(), '..', 'dataset'))\n",
    "\n",
    "# Path ke data dan model yang sudah dilatih\n",
    "X_DATA_PATH = os.path.join(BASE_DIR_DATASET, 'X_data.npy')\n",
    "Y_LABELS_PATH = os.path.join(BASE_DIR_DATASET, 'Y_labels.npy')\n",
    "CHECKPOINT_PATH = os.path.join(BASE_DIR_DATASET, 'checkpoints', 'best_model.h5')\n",
    "\n",
    "IMG_SIZE = (224, 224) # Ukuran gambar target model\n",
    "RANDOM_SEED = 42 # Seed untuk reproduksibilitas split\n",
    "\n",
    "# Direktori untuk menyimpan hasil evaluasi\n",
    "EVAL_RESULTS_DIR = os.path.join(os.getcwd(), 'evaluation_results')\n",
    "os.makedirs(EVAL_RESULTS_DIR, exist_ok=True) # Pastikan direktori ada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data dan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "--- BAGIAN 1: MEMUAT DATA DAN MODEL UNTUK EVALUASI ---\n",
      "==================================================\n",
      "\n",
      "--- 1. Memuat Data X_data.npy dan Y_labels.npy ---\n",
      "Data X.npy dimuat dengan bentuk: (4992, 224, 224, 3)\n",
      "Data Y.npy dimuat dengan bentuk: (4992, 8)\n",
      "\n",
      "--- 2. Membagi Data menjadi Train, Validation, dan Test Set (untuk konsistensi) ---\n",
      "Bentuk data uji (X_test, y_test): (749, 224, 224, 3), (749, 8)\n",
      "\n",
      "--- 3. Memuat Model Terbaik dari Checkpoint ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model terbaik berhasil dimuat kembali dari: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\dataset\\checkpoints\\best_model.h5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_flip (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomFlip</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_rotation                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomRotation</span>)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_zoom (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomZoom</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,248</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_flip (\u001b[38;5;33mRandomFlip\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_rotation                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mRandomRotation\u001b[0m)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_zoom (\u001b[38;5;33mRandomZoom\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │        \u001b[38;5;34m10,248\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,268,234</span> (8.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,268,234\u001b[0m (8.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,248</span> (40.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,248\u001b[0m (40.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(\"=\"*50)\n",
    "print(\"--- BAGIAN 1: MEMUAT DATA DAN MODEL UNTUK EVALUASI ---\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- 1. Memuat Data yang Sudah Diproses (NumPy Arrays) ---\n",
    "print(\"\\n--- 1. Memuat Data X_data.npy dan Y_labels.npy ---\")\n",
    "try:\n",
    "    X = np.load(X_DATA_PATH)\n",
    "    Y = np.load(Y_LABELS_PATH)\n",
    "    print(f\"Data X.npy dimuat dengan bentuk: {X.shape}\")\n",
    "    print(f\"Data Y.npy dimuat dengan bentuk: {Y.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File '{X_DATA_PATH}' atau '{Y_LABELS_PATH}' tidak ditemukan.\")\n",
    "    print(\"Pastikan Anda sudah menjalankan skrip preprocessing dan menyimpannya.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Split Data (Ulangi split yang sama dengan pelatihan untuk mendapatkan Test Set) ---\n",
    "print(\"\\n--- 2. Membagi Data menjadi Train, Validation, dan Test Set (untuk konsistensi) ---\")\n",
    "# Split awal untuk train + val vs test (15% untuk test)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, Y, test_size=0.15, random_state=RANDOM_SEED, shuffle=True)\n",
    "# Split train_val menjadi train dan val (tidak digunakan di sini, tapi dipertahankan untuk konsistensi)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=RANDOM_SEED, shuffle=True)\n",
    "\n",
    "print(f\"Bentuk data uji (X_test, y_test): {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "\n",
    "# --- 3. Memuat Model Terbaik yang Sudah Dilatih ---\n",
    "print(\"\\n--- 3. Memuat Model Terbaik dari Checkpoint ---\")\n",
    "try:\n",
    "    best_model = tf.keras.models.load_model(CHECKPOINT_PATH)\n",
    "    print(f\"Model terbaik berhasil dimuat kembali dari: {CHECKPOINT_PATH}\")\n",
    "    best_model.summary()\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Gagal memuat model terbaik dari '{CHECKPOINT_PATH}'.\")\n",
    "    print(f\"Pesan Error: {e}\")\n",
    "    print(\"Pastikan Anda sudah menjalankan skrip pelatihan dan model disimpan dengan benar.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediksi dan Evaluasi Dasar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================\n",
      "--- BAGIAN 2: PREDIKSI DAN EVALUASI DASAR ---\n",
      "==================================================\n",
      "\n",
      "--- 1. Melakukan Prediksi Probabilitas pada Test Set ---\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 686ms/step\n",
      "Bentuk probabilitas prediksi: (749, 8)\n",
      "Contoh Probabilitas Prediksi (5 sampel pertama):\n",
      " [[0.295 0.931 0.292 0.383 0.285 0.369 0.18  0.512]\n",
      " [0.711 0.25  0.48  0.427 0.534 0.293 0.188 0.4  ]\n",
      " [0.24  0.114 0.274 0.845 0.373 0.398 0.519 0.514]\n",
      " [0.108 0.692 0.381 0.378 0.267 0.626 0.419 0.789]\n",
      " [0.016 0.071 0.145 0.978 0.111 0.528 0.293 0.445]]\n",
      "\n",
      "--- 2. Menerapkan Threshold 0.5 untuk Prediksi Biner ---\n",
      "Contoh Prediksi Biner (5 sampel pertama):\n",
      " [[0 1 0 0 0 0 0 1]\n",
      " [1 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 1 1]\n",
      " [0 1 0 0 0 1 0 1]\n",
      " [0 0 0 1 0 1 0 0]]\n",
      "Contoh Label Sebenarnya (5 sampel pertama):\n",
      " [[1 1 1 0 0 1 0 0]\n",
      " [1 0 1 1 0 1 0 0]\n",
      " [0 0 1 1 1 0 0 1]\n",
      " [0 1 0 0 1 0 1 1]\n",
      " [0 0 0 1 0 0 1 1]]\n",
      "\n",
      "--- 3. Evaluasi Model dengan Metrik yang Digunakan Saat Pelatihan ---\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 706ms/step - auc: 0.8069 - binary_accuracy: 0.7452 - loss: 0.5124 - precision: 0.7558 - recall: 0.4515\n",
      "\n",
      "Hasil Evaluasi pada Test Set:\n",
      "- loss: 0.5140\n",
      "- compile_metrics: 0.7425\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\" + \"=\"*50)\n",
    "print(\"--- BAGIAN 2: PREDIKSI DAN EVALUASI DASAR ---\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- 1. Melakukan Prediksi Probabilitas pada Test Set ---\n",
    "print(\"\\n--- 1. Melakukan Prediksi Probabilitas pada Test Set ---\")\n",
    "y_pred_proba = best_model.predict(X_test, verbose=1)\n",
    "print(f\"Bentuk probabilitas prediksi: {y_pred_proba.shape}\")\n",
    "print(\"Contoh Probabilitas Prediksi (5 sampel pertama):\\n\", y_pred_proba[:5].round(3))\n",
    "\n",
    "\n",
    "# --- 2. Thresholding Standar (0.5) ---\n",
    "# Mengonversi probabilitas menjadi label biner dengan threshold 0.5\n",
    "print(\"\\n--- 2. Menerapkan Threshold 0.5 untuk Prediksi Biner ---\")\n",
    "threshold = 0.5\n",
    "y_pred_thresholded = (y_pred_proba > threshold).astype(int)\n",
    "print(\"Contoh Prediksi Biner (5 sampel pertama):\\n\", y_pred_thresholded[:5])\n",
    "print(\"Contoh Label Sebenarnya (5 sampel pertama):\\n\", y_test[:5].astype(int))\n",
    "\n",
    "# --- 3. Evaluasi Model pada Test Set (Metrik dari Keras) ---\n",
    "print(\"\\n--- 3. Evaluasi Model dengan Metrik yang Digunakan Saat Pelatihan ---\")\n",
    "evaluation_results = best_model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "metrics_names = best_model.metrics_names\n",
    "print(\"\\nHasil Evaluasi pada Test Set:\")\n",
    "for name, value in zip(metrics_names, evaluation_results):\n",
    "    print(f\"- {name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluasi Mendalam Multi-Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================\n",
      "--- BAGIAN 3: EVALUASI MENDALAM MODEL MULTI-LABEL ---\n",
      "==================================================\n",
      "\n",
      "--- 1. Classification Report (per Label, Threshold 0.5) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     battery       0.91      0.45      0.60       260\n",
      "     organik       0.89      0.74      0.81       268\n",
      "       glass       0.73      0.27      0.40       273\n",
      "   cardboard       0.73      0.65      0.69       291\n",
      "       metal       0.74      0.41      0.53       290\n",
      "       paper       0.74      0.33      0.46       275\n",
      "     plastic       0.73      0.32      0.45       279\n",
      "       trash       0.59      0.37      0.46       277\n",
      "\n",
      "   micro avg       0.76      0.44      0.56      2213\n",
      "   macro avg       0.76      0.44      0.55      2213\n",
      "weighted avg       0.76      0.44      0.55      2213\n",
      " samples avg       0.72      0.45      0.53      2213\n",
      "\n",
      "Classification Report (threshold 0.5) disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\classification_report_threshold_05.txt\n",
      "\n",
      "--- 2. Ringkasan Metrik Agregat (dari Classification Report) ---\n",
      "Micro Avg Precision: 0.7589\n",
      "Micro Avg Recall:    0.4437\n",
      "Micro Avg F1-Score:  0.5600\n",
      "\n",
      "Macro Avg Precision: 0.7583\n",
      "Macro Avg Recall:    0.4435\n",
      "Macro Avg F1-Score:  0.5484\n",
      "\n",
      "Weighted Avg Precision: 0.7563\n",
      "Weighted Avg Recall:    0.4437\n",
      "Weighted Avg F1-Score:  0.5479\n",
      "\n",
      "--- 3. Overall ROC AUC Score (Macro & Weighted) ---\n",
      "Overall ROC AUC (Macro): 0.8027\n",
      "Overall ROC AUC (Weighted): 0.8016\n",
      "\n",
      "--- 4. Confusion Matrix (per Label, Threshold 0.5) ---\n",
      "\n",
      "Label: battery\n",
      "[[478  11]\n",
      " [144 116]]\n",
      "Confusion Matrix untuk battery disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\confusion_matrix_battery_05_threshold.png\n",
      "\n",
      "Label: organik\n",
      "[[457  24]\n",
      " [ 71 197]]\n",
      "Confusion Matrix untuk organik disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\confusion_matrix_organik_05_threshold.png\n",
      "\n",
      "Label: glass\n",
      "[[448  28]\n",
      " [198  75]]\n",
      "Confusion Matrix untuk glass disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\confusion_matrix_glass_05_threshold.png\n",
      "\n",
      "Label: cardboard\n",
      "[[387  71]\n",
      " [102 189]]\n",
      "Confusion Matrix untuk cardboard disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\confusion_matrix_cardboard_05_threshold.png\n",
      "\n",
      "Label: metal\n",
      "[[417  42]\n",
      " [170 120]]\n",
      "Confusion Matrix untuk metal disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\confusion_matrix_metal_05_threshold.png\n",
      "\n",
      "Label: paper\n",
      "[[442  32]\n",
      " [183  92]]\n",
      "Confusion Matrix untuk paper disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\confusion_matrix_paper_05_threshold.png\n",
      "\n",
      "Label: plastic\n",
      "[[437  33]\n",
      " [189  90]]\n",
      "Confusion Matrix untuk plastic disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\confusion_matrix_plastic_05_threshold.png\n",
      "\n",
      "Label: trash\n",
      "[[401  71]\n",
      " [174 103]]\n",
      "Confusion Matrix untuk trash disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\confusion_matrix_trash_05_threshold.png\n",
      "\n",
      "--- 5. ROC AUC Score (per Label) ---\n",
      "- battery   : AUC = 0.8825\n",
      "- organik   : AUC = 0.9193\n",
      "- glass     : AUC = 0.7826\n",
      "- cardboard : AUC = 0.8409\n",
      "- metal     : AUC = 0.7686\n",
      "- paper     : AUC = 0.7695\n",
      "- plastic   : AUC = 0.7466\n",
      "- trash     : AUC = 0.7114\n",
      "\n",
      "--- 6. Mencari Threshold Optimal (Maksimalkan F1-Score) per Label ---\n",
      "- battery   : Optimal Threshold = 0.2350 (F1-score maks: 0.7445)\n",
      "- organik   : Optimal Threshold = 0.4244 (F1-score maks: 0.8070)\n",
      "- glass     : Optimal Threshold = 0.1941 (F1-score maks: 0.6528)\n",
      "- cardboard : Optimal Threshold = 0.3981 (F1-score maks: 0.7212)\n",
      "- metal     : Optimal Threshold = 0.2618 (F1-score maks: 0.6601)\n",
      "- paper     : Optimal Threshold = 0.2087 (F1-score maks: 0.6568)\n",
      "- plastic   : Optimal Threshold = 0.2284 (F1-score maks: 0.6226)\n",
      "- trash     : Optimal Threshold = 0.2630 (F1-score maks: 0.6138)\n",
      "Threshold optimal disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\optimal_thresholds.json\n",
      "\n",
      "--- 7. Classification Report (per Label, Threshold Optimal) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     battery       0.71      0.78      0.74       260\n",
      "     organik       0.84      0.77      0.80       268\n",
      "       glass       0.52      0.86      0.65       273\n",
      "   cardboard       0.67      0.77      0.72       291\n",
      "       metal       0.56      0.80      0.66       290\n",
      "       paper       0.55      0.81      0.65       275\n",
      "     plastic       0.50      0.81      0.62       279\n",
      "       trash       0.47      0.86      0.61       277\n",
      "\n",
      "   micro avg       0.58      0.81      0.67      2213\n",
      "   macro avg       0.60      0.81      0.68      2213\n",
      "weighted avg       0.60      0.81      0.68      2213\n",
      " samples avg       0.61      0.80      0.67      2213\n",
      "\n",
      "Classification Report (threshold optimal) disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\classification_report_threshold_optimal.txt\n",
      "\n",
      "--- 8. Perbandingan F1-Score (0.5 threshold vs Optimal threshold) ---\n",
      "- battery   : F1 (0.5) = 0.5995, F1 (Optimal) = 0.7422\n",
      "- organik   : F1 (0.5) = 0.8057, F1 (Optimal) = 0.8047\n",
      "- glass     : F1 (0.5) = 0.3989, F1 (Optimal) = 0.6509\n",
      "- cardboard : F1 (0.5) = 0.6860, F1 (Optimal) = 0.7191\n",
      "- metal     : F1 (0.5) = 0.5310, F1 (Optimal) = 0.6582\n",
      "- paper     : F1 (0.5) = 0.4612, F1 (Optimal) = 0.6549\n",
      "- plastic   : F1 (0.5) = 0.4478, F1 (Optimal) = 0.6207\n",
      "- trash     : F1 (0.5) = 0.4568, F1 (Optimal) = 0.6120\n",
      "\n",
      "Macro F1-score (Optimal Threshold): 0.6828\n",
      "\n",
      "--- 9. Analisis Performa Berdasarkan Jumlah Label per Gambar ---\n",
      "\n",
      "Gambar dengan 2.0 label:\n",
      "  - Jumlah Sampel: 267\n",
      "  - Binary Accuracy (optimal threshold): 0.7626\n",
      "\n",
      "Gambar dengan 3.0 label:\n",
      "  - Jumlah Sampel: 249\n",
      "  - Binary Accuracy (optimal threshold): 0.7008\n",
      "\n",
      "Gambar dengan 4.0 label:\n",
      "  - Jumlah Sampel: 233\n",
      "  - Binary Accuracy (optimal threshold): 0.6690\n",
      "\n",
      "--- Logging Metrik Per Label ke CSV ---\n",
      "Metrik per label (optimal threshold) disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\label_metrics_optimal_threshold.csv\n",
      "Performa berdasarkan jumlah label disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\performance_by_num_labels.csv\n",
      "\n",
      "--- 10. Visualisasi Precision-Recall Curve (per Label) ---\n",
      "Precision-Recall Curve untuk battery disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\precision_recall_curve_battery.png\n",
      "Precision-Recall Curve untuk organik disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\precision_recall_curve_organik.png\n",
      "Precision-Recall Curve untuk glass disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\precision_recall_curve_glass.png\n",
      "Precision-Recall Curve untuk cardboard disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\precision_recall_curve_cardboard.png\n",
      "Precision-Recall Curve untuk metal disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\precision_recall_curve_metal.png\n",
      "Precision-Recall Curve untuk paper disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\precision_recall_curve_paper.png\n",
      "Precision-Recall Curve untuk plastic disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\precision_recall_curve_plastic.png\n",
      "Precision-Recall Curve untuk trash disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\precision_recall_curve_trash.png\n",
      "\n",
      "--- 11. Visualisasi Beberapa Kesalahan Prediksi ---\n",
      "\n",
      "[Contoh 1] Index: 0\n",
      "  True Labels     : ['battery', 'organik', 'glass', 'paper']\n",
      "  Predicted Labels: ['battery', 'organik', 'glass', 'metal', 'paper', 'trash']\n",
      "Gambar kesalahan 1 disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\error_sample_1.png\n",
      "\n",
      "[Contoh 2] Index: 1\n",
      "  True Labels     : ['battery', 'glass', 'cardboard', 'paper']\n",
      "  Predicted Labels: ['battery', 'glass', 'cardboard', 'metal', 'paper', 'trash']\n",
      "Gambar kesalahan 2 disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\error_sample_2.png\n",
      "\n",
      "[Contoh 3] Index: 2\n",
      "  True Labels     : ['glass', 'cardboard', 'metal', 'trash']\n",
      "  Predicted Labels: ['battery', 'glass', 'cardboard', 'metal', 'paper', 'plastic', 'trash']\n",
      "Gambar kesalahan 3 disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\error_sample_3.png\n",
      "\n",
      "[Contoh 4] Index: 3\n",
      "  True Labels     : ['organik', 'metal', 'plastic', 'trash']\n",
      "  Predicted Labels: ['organik', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
      "Gambar kesalahan 4 disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\error_sample_4.png\n",
      "\n",
      "[Contoh 5] Index: 4\n",
      "  True Labels     : ['cardboard', 'plastic', 'trash']\n",
      "  Predicted Labels: ['cardboard', 'paper', 'plastic', 'trash']\n",
      "Gambar kesalahan 5 disimpan ke: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\\error_sample_5.png\n",
      "\n",
      "--- Evaluasi Model Multi-Label Selesai ---\n",
      "\n",
      "Semua hasil evaluasi (laporan, threshold, grafik, gambar kesalahan) tersimpan di direktori: d:\\Kuroya\\Kuliah\\sampah-multilabel-ai\\notebook\\evaluation_results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n\\n\" + \"=\"*50)\n",
    "print(\"--- BAGIAN 3: EVALUASI MENDALAM MODEL MULTI-LABEL ---\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- 1. Classification Report: Precision, Recall, F1-Score per Label (Threshold 0.5) ---\n",
    "print(\"\\n--- 1. Classification Report (per Label, Threshold 0.5) ---\")\n",
    "report_05 = classification_report(y_test, y_pred_thresholded, target_names=LABELS_FINAL, zero_division=0)\n",
    "print(report_05)\n",
    "\n",
    "# --- Tambahan: Simpan Classification Report 0.5 ---\n",
    "report_05_filename = os.path.join(EVAL_RESULTS_DIR, \"classification_report_threshold_05.txt\")\n",
    "with open(report_05_filename, \"w\") as f:\n",
    "    f.write(report_05)\n",
    "print(f\"Classification Report (threshold 0.5) disimpan ke: {report_05_filename}\")\n",
    "\n",
    "\n",
    "# --- 2. Ringkasan Metrik Agregat (dari Classification Report) ---\n",
    "print(\"\\n--- 2. Ringkasan Metrik Agregat (dari Classification Report) ---\")\n",
    "report_dict_05 = classification_report(y_test, y_pred_thresholded, target_names=LABELS_FINAL, output_dict=True, zero_division=0)\n",
    "\n",
    "print(f\"Micro Avg Precision: {report_dict_05['micro avg']['precision']:.4f}\")\n",
    "print(f\"Micro Avg Recall:    {report_dict_05['micro avg']['recall']:.4f}\")\n",
    "print(f\"Micro Avg F1-Score:  {report_dict_05['micro avg']['f1-score']:.4f}\")\n",
    "\n",
    "print(f\"\\nMacro Avg Precision: {report_dict_05['macro avg']['precision']:.4f}\")\n",
    "print(f\"Macro Avg Recall:    {report_dict_05['macro avg']['recall']:.4f}\")\n",
    "print(f\"Macro Avg F1-Score:  {report_dict_05['macro avg']['f1-score']:.4f}\")\n",
    "\n",
    "print(f\"\\nWeighted Avg Precision: {report_dict_05['weighted avg']['precision']:.4f}\")\n",
    "print(f\"Weighted Avg Recall:    {report_dict_05['weighted avg']['recall']:.4f}\")\n",
    "print(f\"Weighted Avg F1-Score:  {report_dict_05['weighted avg']['f1-score']:.4f}\")\n",
    "\n",
    "# --- 3. Overall ROC AUC Score (Macro & Weighted) ---\n",
    "print(\"\\n--- 3. Overall ROC AUC Score (Macro & Weighted) ---\")\n",
    "overall_auc_macro = roc_auc_score(y_test, y_pred_proba, average='macro')\n",
    "overall_auc_weighted = roc_auc_score(y_test, y_pred_proba, average='weighted')\n",
    "print(f\"Overall ROC AUC (Macro): {overall_auc_macro:.4f}\")\n",
    "print(f\"Overall ROC AUC (Weighted): {overall_auc_weighted:.4f}\")\n",
    "\n",
    "\n",
    "# --- 4. Confusion Matrix per Label (Threshold 0.5) ---\n",
    "print(\"\\n--- 4. Confusion Matrix (per Label, Threshold 0.5) ---\")\n",
    "for i, label in enumerate(LABELS_FINAL):\n",
    "    cm = confusion_matrix(y_test[:, i], y_pred_thresholded[:, i])\n",
    "    print(f\"\\nLabel: {label}\")\n",
    "    print(cm)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not \" + label, label])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f'Confusion Matrix - {label}')\n",
    "    plt.grid(False)\n",
    "    # Simpan Confusion Matrix Plot\n",
    "    cm_filename = os.path.join(EVAL_RESULTS_DIR, f\"confusion_matrix_{label}_05_threshold.png\")\n",
    "    plt.savefig(cm_filename)\n",
    "    plt.close() # Tutup plot agar tidak menumpuk di memori jika banyak label\n",
    "    print(f\"Confusion Matrix untuk {label} disimpan ke: {cm_filename}\")\n",
    "\n",
    "# --- 5. ROC AUC Score per Label ---\n",
    "print(\"\\n--- 5. ROC AUC Score (per Label) ---\")\n",
    "for i, label in enumerate(LABELS_FINAL):\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test[:, i], y_pred_proba[:, i])\n",
    "        print(f\"- {label:<10}: AUC = {auc:.4f}\")\n",
    "    except ValueError:\n",
    "        print(f\"- {label:<10}: AUC tidak dapat dihitung (label terlalu imbalanced atau konstan)\")\n",
    "\n",
    "# --- 6. Mencari Threshold Optimal per Label (Maksimalkan F1-Score) ---\n",
    "print(\"\\n--- 6. Mencari Threshold Optimal (Maksimalkan F1-Score) per Label ---\")\n",
    "optimal_thresholds = {}\n",
    "for i, label in enumerate(LABELS_FINAL):\n",
    "    precisions, recalls, thresholds_arr = precision_recall_curve(y_test[:, i], y_pred_proba[:, i])\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10) # Tambah epsilon untuk menghindari ZeroDivisionError\n",
    "\n",
    "    if len(f1_scores) > 0:\n",
    "        optimal_idx = np.argmax(f1_scores)\n",
    "        # CONVERT TO STANDARD PYTHON FLOAT HERE\n",
    "        optimal_thresholds[label] = float(thresholds_arr[optimal_idx]) if optimal_idx < len(thresholds_arr) else float(thresholds_arr[-1])\n",
    "        print(f\"- {label:<10}: Optimal Threshold = {optimal_thresholds[label]:.4f} (F1-score maks: {f1_scores[optimal_idx]:.4f})\")\n",
    "    else:\n",
    "        print(f\"- {label:<10}: Tidak dapat menemukan F1-score optimal (data tidak cukup bervariasi).\")\n",
    "\n",
    "# --- Tambahan: Simpan Threshold Optimal ---\n",
    "optimal_thresholds_filename = os.path.join(EVAL_RESULTS_DIR, \"optimal_thresholds.json\")\n",
    "with open(optimal_thresholds_filename, \"w\") as f:\n",
    "    json.dump(optimal_thresholds, f, indent=2)\n",
    "print(f\"Threshold optimal disimpan ke: {optimal_thresholds_filename}\")\n",
    "\n",
    "\n",
    "# --- 7. Classification Report dengan Threshold Optimal ---\n",
    "print(\"\\n--- 7. Classification Report (per Label, Threshold Optimal) ---\")\n",
    "y_pred_optimal_thresholded = np.zeros_like(y_pred_proba, dtype=int)\n",
    "for i, label in enumerate(LABELS_FINAL):\n",
    "    if label in optimal_thresholds:\n",
    "        y_pred_optimal_thresholded[:, i] = (y_pred_proba[:, i] > optimal_thresholds[label]).astype(int)\n",
    "    else:\n",
    "        y_pred_optimal_thresholded[:, i] = (y_pred_proba[:, i] > 0.5).astype(int)\n",
    "\n",
    "report_optimal = classification_report(y_test, y_pred_optimal_thresholded, target_names=LABELS_FINAL, zero_division=0)\n",
    "print(report_optimal)\n",
    "\n",
    "# --- Tambahan: Simpan Classification Report Optimal ---\n",
    "report_optimal_filename = os.path.join(EVAL_RESULTS_DIR, \"classification_report_threshold_optimal.txt\")\n",
    "with open(report_optimal_filename, \"w\") as f:\n",
    "    f.write(report_optimal)\n",
    "print(f\"Classification Report (threshold optimal) disimpan ke: {report_optimal_filename}\")\n",
    "\n",
    "\n",
    "# --- 8. Perbandingan F1-Score (0.5 threshold vs Optimal threshold) ---\n",
    "print(\"\\n--- 8. Perbandingan F1-Score (0.5 threshold vs Optimal threshold) ---\")\n",
    "report_05_dict = classification_report(y_test, y_pred_thresholded, target_names=LABELS_FINAL, output_dict=True, zero_division=0)\n",
    "report_optimal_dict = classification_report(y_test, y_pred_optimal_thresholded, target_names=LABELS_FINAL, output_dict=True, zero_division=0)\n",
    "\n",
    "for label in LABELS_FINAL:\n",
    "    f1_05 = report_05_dict[label]['f1-score'] if label in report_05_dict else 0.0\n",
    "    f1_opt = report_optimal_dict[label]['f1-score'] if label in report_optimal_dict else 0.0\n",
    "    print(f\"- {label:<10}: F1 (0.5) = {f1_05:.4f}, F1 (Optimal) = {f1_opt:.4f}\")\n",
    "\n",
    "# --- Tambahan: F1 Macro Score secara Manual dari Optimal ---\n",
    "macro_f1_optimal = np.mean([report_optimal_dict[label]['f1-score'] for label in LABELS_FINAL if label in report_optimal_dict and 'f1-score' in report_optimal_dict[label]])\n",
    "print(f\"\\nMacro F1-score (Optimal Threshold): {macro_f1_optimal:.4f}\")\n",
    "\n",
    "\n",
    "# --- 9. Analisis Performa Berdasarkan Jumlah Label per Gambar ---\n",
    "print(\"\\n--- 9. Analisis Performa Berdasarkan Jumlah Label per Gambar ---\")\n",
    "\n",
    "num_true_labels_test = np.sum(y_test, axis=1)\n",
    "unique_num_labels = np.unique(num_true_labels_test)\n",
    "\n",
    "performance_by_num_labels = [] # Untuk menyimpan hasil dalam bentuk tabel/dict\n",
    "\n",
    "for n_labels in sorted(unique_num_labels):\n",
    "    if n_labels == 0: continue\n",
    "    \n",
    "    indices = np.where(num_true_labels_test == n_labels)[0]\n",
    "    \n",
    "    if len(indices) == 0:\n",
    "        continue\n",
    "    \n",
    "    subset_y_test = y_test[indices]\n",
    "    subset_y_pred = y_pred_optimal_thresholded[indices]\n",
    "    \n",
    "    subset_binary_accuracy = np.mean(subset_y_test == subset_y_pred) \n",
    "    \n",
    "    print(f\"\\nGambar dengan {n_labels} label:\")\n",
    "    print(f\"  - Jumlah Sampel: {len(indices)}\")\n",
    "    print(f\"  - Binary Accuracy (optimal threshold): {subset_binary_accuracy:.4f}\")\n",
    "    performance_by_num_labels.append({\n",
    "        'num_labels': n_labels,\n",
    "        'num_samples': len(indices),\n",
    "        'binary_accuracy_optimal_threshold': subset_binary_accuracy\n",
    "    })\n",
    "\n",
    "# --- Tambahan: Logging ke CSV untuk Metrik Per Label (dari threshold optimal) ---\n",
    "print(\"\\n--- Logging Metrik Per Label ke CSV ---\")\n",
    "label_metrics_df = pd.DataFrame.from_dict(report_optimal_dict, orient='index')\n",
    "# Hapus baris 'accuracy', 'macro avg', 'weighted avg', 'samples' jika tidak ingin disimpan\n",
    "label_metrics_df = label_metrics_df.drop(columns=['support'], errors='ignore') # 'support' juga bisa dihapus\n",
    "label_metrics_df = label_metrics_df.drop(index=['accuracy', 'macro avg', 'weighted avg'], errors='ignore')\n",
    "label_metrics_df.index.name = 'label' # Beri nama kolom indeks\n",
    "\n",
    "label_metrics_filename = os.path.join(EVAL_RESULTS_DIR, \"label_metrics_optimal_threshold.csv\")\n",
    "label_metrics_df.to_csv(label_metrics_filename)\n",
    "print(f\"Metrik per label (optimal threshold) disimpan ke: {label_metrics_filename}\")\n",
    "\n",
    "# Optional: Simpan juga performa berdasarkan jumlah label\n",
    "performance_num_labels_df = pd.DataFrame(performance_by_num_labels)\n",
    "performance_num_labels_filename = os.path.join(EVAL_RESULTS_DIR, \"performance_by_num_labels.csv\")\n",
    "performance_num_labels_df.to_csv(performance_num_labels_filename, index=False)\n",
    "print(f\"Performa berdasarkan jumlah label disimpan ke: {performance_num_labels_filename}\")\n",
    "\n",
    "\n",
    "# --- 10. Visualisasi Kurva Precision-Recall per Label ---\n",
    "print(\"\\n--- 10. Visualisasi Precision-Recall Curve (per Label) ---\")\n",
    "\n",
    "for i, label in enumerate(LABELS_FINAL):\n",
    "    precisions, recalls, _ = precision_recall_curve(y_test[:, i], y_pred_proba[:, i])\n",
    "    \n",
    "    plt.figure(figsize=(7, 6))\n",
    "    disp = PrecisionRecallDisplay(precision=precisions, recall=recalls)\n",
    "    disp.plot()\n",
    "    plt.title(f'Precision-Recall Curve - {label}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Simpan Precision-Recall Curve Plot\n",
    "    pr_curve_filename = os.path.join(EVAL_RESULTS_DIR, f\"precision_recall_curve_{label}.png\")\n",
    "    plt.savefig(pr_curve_filename)\n",
    "    plt.close()\n",
    "    print(f\"Precision-Recall Curve untuk {label} disimpan ke: {pr_curve_filename}\")\n",
    "\n",
    "\n",
    "# --- 11. Visualisasi Beberapa Kesalahan Prediksi ---\n",
    "print(\"\\n--- 11. Visualisasi Beberapa Kesalahan Prediksi ---\")\n",
    "\n",
    "samples_shown = 0\n",
    "max_errors = 5\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    true = y_test[i]\n",
    "    pred = y_pred_optimal_thresholded[i]\n",
    "    \n",
    "    if not np.array_equal(true, pred):\n",
    "        print(f\"\\n[Contoh {samples_shown+1}] Index: {i}\")\n",
    "        true_labels = [LABELS_FINAL[j] for j in range(len(LABELS_FINAL)) if true[j] == 1]\n",
    "        predicted_labels = [LABELS_FINAL[j] for j in range(len(LABELS_FINAL)) if pred[j] == 1]\n",
    "        \n",
    "        print(f\"  True Labels     : {true_labels}\")\n",
    "        print(f\"  Predicted Labels: {predicted_labels}\")\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(X_test[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"True: {', '.join(true_labels)}\\nPred: {', '.join(predicted_labels)}\", fontsize=12, color='red', wrap=True)\n",
    "        \n",
    "        # Simpan Gambar Kesalahan Prediksi\n",
    "        error_img_filename = os.path.join(EVAL_RESULTS_DIR, f\"error_sample_{samples_shown+1}.png\")\n",
    "        plt.savefig(error_img_filename)\n",
    "        plt.close()\n",
    "        print(f\"Gambar kesalahan {samples_shown+1} disimpan ke: {error_img_filename}\")\n",
    "        \n",
    "        samples_shown += 1\n",
    "        if samples_shown >= max_errors:\n",
    "            break\n",
    "\n",
    "print(\"\\n--- Evaluasi Model Multi-Label Selesai ---\")\n",
    "print(f\"\\nSemua hasil evaluasi (laporan, threshold, grafik, gambar kesalahan) tersimpan di direktori: {EVAL_RESULTS_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ai_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
